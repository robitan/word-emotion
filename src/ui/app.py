"""
æ¯”è¼ƒUIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

Streamlitã‚’ä½¿ç”¨ã—ã¦ã€ç•°ãªã‚‹ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã¨CAåˆ†æçµæœã‚’æ¯”è¼ƒãƒ»å¯è¦–åŒ–ã™ã‚‹ã€‚
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import numpy as np

from src.data_loader import EmotionDataLoader
from src.embedding import EmbeddingModel
from src.vector_db import VectorDB
from src.analysis.correspondence import CorrespondenceAnalysis
from src.analysis.evaluation import StructureEvaluator
from src.training.triplet import compute_emotion_vector


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å˜èªÃ—æ„Ÿæƒ… ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“æ¯”è¼ƒã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'ca_fitted' not in st.session_state:
    st.session_state.ca_fitted = False


@st.cache_resource
def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    loader = EmotionDataLoader()
    data = loader.load_all()
    return data, loader


@st.cache_resource
def load_models():
    """ãƒ¢ãƒ‡ãƒ«ã¨DBã‚’èª­ã¿è¾¼ã‚€"""
    embedding_model = EmbeddingModel()
    db = VectorDB()
    return embedding_model, db


@st.cache_resource
def fit_ca(_data):
    """ã‚³ãƒ¬ã‚¹ãƒãƒ³ãƒ‡ãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ"""
    ca = CorrespondenceAnalysis(n_components=2)
    ca.fit(_data['contingency_table'])
    return ca


def main():
    st.title("ğŸ“Š å˜èª Ã— æ„Ÿæƒ… ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“æ¯”è¼ƒã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
        data, loader = load_data()
        embedding_model, db = load_models()
        ca = fit_ca(data)

    st.session_state.data_loaded = True
    st.session_state.ca_fitted = True

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("è¨­å®š")

    # ãƒšãƒ¼ã‚¸é¸æŠ
    page = st.sidebar.selectbox(
        "æ©Ÿèƒ½ã‚’é¸æŠ",
        ["é¡ä¼¼æ¤œç´¢", "æ„Ÿæƒ…å¤‰åŒ–æ¤œç´¢", "CAå¯è¦–åŒ–", "æ§‹é€ æ•´åˆæ€§è©•ä¾¡"]
    )

    # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã‚’è¡¨ç¤º
    st.sidebar.markdown("---")
    st.sidebar.subheader("ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
    st.sidebar.metric("å˜èªæ•°", len(data['word_emotions']))
    st.sidebar.metric("æ„Ÿæƒ…ã‚«ãƒ†ã‚´ãƒªæ•°", len(data['emotion_map']))
    st.sidebar.metric("Positive pairs", len(data['positive_pairs']))
    st.sidebar.metric("Negative pairs", len(data['negative_pairs']))

    # ãƒšãƒ¼ã‚¸ã”ã¨ã®å‡¦ç†
    if page == "é¡ä¼¼æ¤œç´¢":
        show_similarity_search(data, embedding_model, db, loader)
    elif page == "æ„Ÿæƒ…å¤‰åŒ–æ¤œç´¢":
        show_emotion_shift_search(data, embedding_model, db, loader, ca)
    elif page == "CAå¯è¦–åŒ–":
        show_ca_visualization(data, ca, loader)
    elif page == "æ§‹é€ æ•´åˆæ€§è©•ä¾¡":
        show_structure_evaluation(data, ca, db, embedding_model, loader)


def show_similarity_search(data, embedding_model, db, loader):
    """é¡ä¼¼æ¤œç´¢ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ” é¡ä¼¼æ¤œç´¢")

    # å…¥åŠ›
    col1, col2 = st.columns([3, 1])

    with col1:
        word = st.text_input("æ¤œç´¢ã™ã‚‹å˜èªã‚’å…¥åŠ›", placeholder="ä¾‹: å–œã³")

    with col2:
        top_k = st.number_input("ä¸Šä½Kä»¶", min_value=1, max_value=50, value=10)

    # DBé¸æŠ
    selected_dbs = st.multiselect(
        "æ¯”è¼ƒã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã‚’é¸æŠ",
        ["Baseline", "BCE", "Triplet"],
        default=["Baseline", "BCE", "Triplet"]
    )

    if st.button("æ¤œç´¢") and word:
        if word not in data['word_emotions']:
            st.error(f"å˜èª '{word}' ã¯ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“")
            return

        # å„DBã§æ¤œç´¢
        results_dict = {}

        for db_name in selected_dbs:
            db_type = db_name.lower()

            try:
                results = db.search_by_word(
                    collection_type=db_type,
                    word=word,
                    embedding_model=embedding_model,
                    top_k=top_k
                )
                results_dict[db_name] = results
            except Exception as e:
                st.warning(f"{db_name} ã§ã®æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # çµæœã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        if results_dict:
            cols = st.columns(len(results_dict))

            for i, (db_name, results) in enumerate(results_dict.items()):
                with cols[i]:
                    st.subheader(f"{db_name}")

                    # çµæœã‚’DataFrameã«å¤‰æ›
                    df_results = []
                    for j, result in enumerate(results):
                        emotions = ', '.join([
                            data['emotion_map'].get(e, e)
                            for e in result['emotions']
                        ])
                        df_results.append({
                            "é †ä½": j + 1,
                            "å˜èª": result['word'],
                            "ã‚¹ã‚³ã‚¢": f"{result['score']:.4f}",
                            "æ„Ÿæƒ…": emotions
                        })

                    st.dataframe(
                        pd.DataFrame(df_results),
                        hide_index=True,
                        use_container_width=True
                    )


def show_emotion_shift_search(data, embedding_model, db, loader, ca):
    """æ„Ÿæƒ…å¤‰åŒ–æ¤œç´¢ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ­ æ„Ÿæƒ…å¤‰åŒ–æ¤œç´¢")

    st.markdown("""
    å˜èªã«æ„Ÿæƒ…æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã‚’åŠ ãˆã‚‹ã“ã¨ã§ã€æ„Ÿæƒ…ã®å¤‰åŒ–ã‚’è¡¨ç¾ã—ã¾ã™ã€‚
    """)

    # å…¥åŠ›
    col1, col2, col3 = st.columns([2, 2, 1])

    with col1:
        word = st.text_input("å…ƒã®å˜èªã‚’å…¥åŠ›", placeholder="ä¾‹: å–œã³")

    with col2:
        # æ„Ÿæƒ…ã‚·ãƒ³ãƒœãƒ«ã®é¸æŠè‚¢ã‚’ä½œæˆ
        emotion_options = {
            data['emotion_map'][symbol]: symbol
            for symbol in data['emotion_map'].keys()
        }
        target_emotion = st.selectbox(
            "ç›®æ¨™ã®æ„Ÿæƒ…ã‚’é¸æŠ",
            options=list(emotion_options.keys())
        )
        target_emotion_symbol = emotion_options[target_emotion]

    with col3:
        lambda_ = st.slider("æ„Ÿæƒ…å¤‰åŒ–ã®å¼·ã• (Î»)", 0.0, 2.0, 1.0, 0.1)

    # DBé¸æŠ
    db_type = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“",
        ["Triplet", "Baseline", "BCE"]
    ).lower()

    top_k = st.number_input("ä¸Šä½Kä»¶", min_value=1, max_value=50, value=10)

    if st.button("æ¤œç´¢") and word:
        if word not in data['word_emotions']:
            st.error(f"å˜èª '{word}' ã¯ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“")
            return

        # ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã‹ã‚‰å…¨å˜èªã®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
        try:
            words, vectors = db.get_all_vectors(db_type)

            # æ„Ÿæƒ…å¤‰åŒ–ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—
            word_embeddings_dict = {w: vectors[i] for i, w in enumerate(words)}

            emotion_vector = compute_emotion_vector(
                word_embeddings=word_embeddings_dict,
                word_emotions=data['word_emotions'],
                emotion_symbol=target_emotion_symbol,
                method="mean_diff"
            )

            # æ„Ÿæƒ…å¤‰åŒ–æ¤œç´¢ã‚’å®Ÿè¡Œ
            results = db.search_with_emotion_shift(
                collection_type=db_type,
                word=word,
                emotion_vector=emotion_vector,
                lambda_=lambda_,
                embedding_model=embedding_model,
                top_k=top_k
            )

            # çµæœã‚’è¡¨ç¤º
            st.subheader(f"çµæœ: '{word}' + {lambda_}Î» Ã— '{target_emotion}'")

            df_results = []
            for j, result in enumerate(results):
                emotions = ', '.join([
                    data['emotion_map'].get(e, e)
                    for e in result['emotions']
                ])
                df_results.append({
                    "é †ä½": j + 1,
                    "å˜èª": result['word'],
                    "ã‚¹ã‚³ã‚¢": f"{result['score']:.4f}",
                    "æ„Ÿæƒ…": emotions
                })

            st.dataframe(
                pd.DataFrame(df_results),
                hide_index=True,
                use_container_width=True
            )

        except Exception as e:
            st.error(f"æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")


def show_ca_visualization(data, ca, loader):
    """CAå¯è¦–åŒ–ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“ˆ ã‚³ãƒ¬ã‚¹ãƒãƒ³ãƒ‡ãƒ³ã‚¹åˆ†æï¼ˆCAï¼‰å¯è¦–åŒ–")

    # CAè¦ç´„ã‚’è¡¨ç¤º
    summary = ca.get_summary()

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å˜èªæ•°", summary['n_words'])
    with col2:
        st.metric("æ„Ÿæƒ…æ•°", summary['n_emotions'])
    with col3:
        st.metric("ç´¯ç©èª¬æ˜ç‡", f"{summary['total_explained']:.2%}")

    # åº§æ¨™ã‚’å–å¾—
    word_coords = ca.get_word_coordinates()
    emotion_coords = ca.get_emotion_coordinates()

    # å¯è¦–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    show_words = st.checkbox("å˜èªã‚’è¡¨ç¤º", value=True)
    show_emotions = st.checkbox("æ„Ÿæƒ…ã‚’è¡¨ç¤º", value=True)

    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig = go.Figure()

    if show_words:
        # å˜èªã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        fig.add_trace(go.Scatter(
            x=word_coords.iloc[:, 0],
            y=word_coords.iloc[:, 1],
            mode='markers+text',
            name='å˜èª',
            text=word_coords.index,
            textposition="top center",
            marker=dict(size=5, color='blue', opacity=0.6),
            textfont=dict(size=8)
        ))

    if show_emotions:
        # æ„Ÿæƒ…ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        # æ„Ÿæƒ…åã«å¤‰æ›
        emotion_names = [data['emotion_map'].get(e, e) for e in emotion_coords.index]

        fig.add_trace(go.Scatter(
            x=emotion_coords.iloc[:, 0],
            y=emotion_coords.iloc[:, 1],
            mode='markers+text',
            name='æ„Ÿæƒ…',
            text=emotion_names,
            textposition="top center",
            marker=dict(size=15, color='red', symbol='diamond', opacity=0.8),
            textfont=dict(size=12, color='red')
        ))

    fig.update_layout(
        title="CA 2æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆ",
        xaxis_title=f"æ¬¡å…ƒ 1 ({summary['explained_inertia'][0]:.2%})",
        yaxis_title=f"æ¬¡å…ƒ 2 ({summary['explained_inertia'][1]:.2%})",
        height=700,
        hovermode='closest'
    )

    st.plotly_chart(fig, use_container_width=True)

    # ç‰¹å®šã®å˜èªã®è¿‘å‚ã‚’è¡¨ç¤º
    st.subheader("å˜èªã®è¿‘å‚åˆ†æ")

    word = st.text_input("åˆ†æã™ã‚‹å˜èªã‚’å…¥åŠ›", placeholder="ä¾‹: å–œã³")
    k = st.number_input("è¿‘å‚æ•°", min_value=1, max_value=20, value=10)

    if word and word in word_coords.index:
        neighbors = ca.get_neighbors(word, k=k, include_emotions=True)

        df_neighbors = pd.DataFrame(neighbors)
        df_neighbors['distance'] = df_neighbors['distance'].apply(lambda x: f"{x:.4f}")

        st.dataframe(df_neighbors, hide_index=True, use_container_width=True)


def show_structure_evaluation(data, ca, db, embedding_model, loader):
    """æ§‹é€ æ•´åˆæ€§è©•ä¾¡ãƒšãƒ¼ã‚¸"""
    st.header("ğŸ“Š æ§‹é€ æ•´åˆæ€§è©•ä¾¡")

    st.markdown("""
    CAã®çµæœã¨ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã®æ§‹é€ ãŒã©ã®ç¨‹åº¦ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚
    """)

    # DBé¸æŠ
    db_type = st.selectbox(
        "è©•ä¾¡ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“",
        ["Baseline", "BCE", "Triplet"]
    ).lower()

    if st.button("è©•ä¾¡ã‚’å®Ÿè¡Œ"):
        with st.spinner("è©•ä¾¡ä¸­..."):
            try:
                # ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã‹ã‚‰å…¨å˜èªã®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
                words, vectors = db.get_all_vectors(db_type)

                # CAåº§æ¨™ã‚’å–å¾—
                ca_coords = ca.get_word_coordinates()

                # è©•ä¾¡å™¨ã‚’ä½œæˆ
                evaluator = StructureEvaluator(
                    ca_word_coords=ca_coords,
                    vector_words=words,
                    vector_embeddings=vectors
                )

                # å…¨è©•ä¾¡ã‚’å®Ÿè¡Œ
                results = evaluator.evaluate_all(k_values=[5, 10, 20])

                # è·é›¢ç›¸é–¢ã‚’è¡¨ç¤º
                st.subheader("1. è·é›¢ç›¸é–¢")

                dist_corr = results['distance_correlation']

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Spearmanç›¸é–¢ä¿‚æ•°", f"{dist_corr['spearman_correlation']:.4f}")
                with col2:
                    st.metric("på€¤", f"{dist_corr['p_value']:.4e}")

                # è¿‘å‚ä¸€è‡´ç‡ã‚’è¡¨ç¤º
                st.subheader("2. è¿‘å‚ä¸€è‡´ç‡")

                overlap_data = []
                for k_name, overlap_result in results['neighbor_overlaps'].items():
                    overlap_data.append({
                        "k": k_name,
                        "å¹³å‡ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—": f"{overlap_result['mean_overlap']:.2f}",
                        "å¹³å‡Jaccardä¿‚æ•°": f"{overlap_result['mean_jaccard']:.4f}"
                    })

                st.dataframe(pd.DataFrame(overlap_data), hide_index=True, use_container_width=True)

                # ç‰¹å®šã®å˜èªã®æ¯”è¼ƒ
                st.subheader("3. å˜èªã”ã¨ã®æ¯”è¼ƒ")

                word = st.text_input("æ¯”è¼ƒã™ã‚‹å˜èªã‚’å…¥åŠ›", placeholder="ä¾‹: å–œã³")
                k_compare = st.number_input("æ¯”è¼ƒã™ã‚‹è¿‘å‚æ•°", min_value=1, max_value=20, value=10)

                if word and word in evaluator.common_words:
                    comparison = evaluator.get_word_comparison(word, k=k_compare)

                    col1, col2 = st.columns(2)

                    with col1:
                        st.write(f"**CAç©ºé–“ã§ã®è¿‘å‚**")
                        df_ca = pd.DataFrame(comparison['ca_neighbors'])
                        df_ca['distance'] = df_ca['distance'].apply(lambda x: f"{x:.4f}")
                        st.dataframe(df_ca, hide_index=True, use_container_width=True)

                    with col2:
                        st.write(f"**ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã§ã®è¿‘å‚**")
                        df_vector = pd.DataFrame(comparison['vector_neighbors'])
                        df_vector['distance'] = df_vector['distance'].apply(lambda x: f"{x:.4f}")
                        st.dataframe(df_vector, hide_index=True, use_container_width=True)

                    st.write(f"**ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—**: {comparison['overlap']}")
                    st.metric("Jaccardä¿‚æ•°", f"{comparison['jaccard']:.4f}")

            except Exception as e:
                st.error(f"è©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    main()
